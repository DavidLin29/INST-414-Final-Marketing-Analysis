# Marketing Conversion Prediction â€“ INST414 Final Project

This project analyzes marketing campaign data to build predictive models that estimate whether a customer will convert based on engagement, demographics, and campaign features.

## ğŸ” Project Overview

We used structured marketing campaign data to train and evaluate multiple predictive models. Our goal was to optimize marketing strategies by identifying the features that drive customer conversions.

This project was developed as part of the final assignment for INST414 â€“ Data Science Methods at the University of Maryland.

## ğŸ§  Problem Statement

Can we predict whether a user will convert based on campaign and customer data?

Marketing teams often spend large sums targeting broad audiences. Predicting likely converters can significantly reduce costs and increase efficiency.

## ğŸ› ï¸ Project Structure

This project follows the Cookiecutter Data Science structure:

â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/             <- Original data
â”‚   â”œâ”€â”€ interim/         <- Cleaned, intermediate datasets
â”‚   â”œâ”€â”€ processed/       <- Final datasets for modeling
â”‚
â”œâ”€â”€ models/              <- Trained model .pkl files
â”œâ”€â”€ reports/
â”‚   â””â”€â”€ figures/         <- Visualizations like ROC curves and confusion matrices
â”‚
â”œâ”€â”€ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
â”‚                         the creator's initials, and a short `-` delimited description, e.g.
â”‚                         `1.0-jqp-initial-data-exploration`.
â”‚
â”œâ”€â”€ pyproject.toml     <- Project configuration file with package metadata for 
â”‚                         Marketing Analysis and configuration for tools like black
â”‚
â”œâ”€â”€ references         <- Data dictionaries, manuals, and all other explanatory materials.
â”‚
â”œâ”€â”€ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
â”‚   â””â”€â”€ figures        <- Generated graphics and figures to be used in reporting
â”‚
â”œâ”€â”€ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
â”‚                         generated with `pip freeze > requirements.txt`
â”‚
â”œâ”€â”€ setup.cfg          <- Configuration file for flake8
â”‚
â””â”€â”€ Marketing Analysis   <- Source code for use in this project.
    â”‚
    â”œâ”€â”€ __init__.py             <- Makes Marketing Analysis a Python module
    â”‚
    â”œâ”€â”€ config.py               <- Store useful variables and configuration
    â”‚
    â”œâ”€â”€ dataset.py              <- Scripts to download or generate data
    â”‚
    â”œâ”€â”€ features.py             <- Code to create features for modeling
    â”‚
    â”œâ”€â”€ modeling                
    â”‚   â”œâ”€â”€ __init__.py 
    â”‚   â”œâ”€â”€ predict.py          <- Code to run model inference with trained models          
    â”‚   â””â”€â”€ train.py            <- Code to train models
    â”‚
    â””â”€â”€ plots.py                <- Code to create visualizations
```

--------

#How to run all the code
# 1. Run dataset cleaning and preparation
python -m marketing_analysis.modeling.dataset

# 2. Generate features
python -m marketing_analysis.modeling.features

# 3. Train all models (Logistic Regression, Random Forest, XGBoost)
python -m marketing_analysis.modeling.train

# 4. Run predictions on test set
python -m marketing_analysis.modeling.predict

# 5. Visualize model performance and do error analysis
python -m marketing_analysis.modeling.visualize_and_error_analysis plot-confusion-matrix
python -m marketing_analysis.modeling.visualize_and_error_analysis plot-roc-curves
python -m marketing_analysis.modeling.visualize_and_error_analysis plot-feature-importance
python -m marketing_analysis.modeling.visualize_and_error_analysis find-errors
â”œâ”€â”€ notebooks/           <- Jupyter notebooks for exploration
â”œâ”€â”€ marketing_analysis/  <- All source code
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ dataset.py
â”‚   â”œâ”€â”€ features.py
â”‚   â”œâ”€â”€ plots.py
â”‚   â””â”€â”€ modeling/
â”‚       â”œâ”€â”€ train.py
â”‚       â”œâ”€â”€ predict.py
â”‚       â””â”€â”€ visualize_and_error_analysis.py

## âš™ï¸ Setup and Usage

### ğŸ“¦ Environment Setup

Use Conda to create the environment:

conda env create -f environment.yml
conda activate marketing_analysis

### â–¶ï¸ Run the Full Pipeline

python -m marketing_analysis.dataset
python -m marketing_analysis.features
python -m marketing_analysis.modeling.train
python -m marketing_analysis.modeling.predict
python -m marketing_analysis.modeling.visualize_and_error_analysis plot-confusion-matrix

Other available visualizations:

python -m marketing_analysis.modeling.visualize_and_error_analysis plot-roc-curves
python -m marketing_analysis.modeling.visualize_and_error_analysis plot-feature-importance
python -m marketing_analysis.modeling.visualize_and_error_analysis find-errors

## ğŸ¤– Models Trained

We implemented and compared three models:

Model               | Accuracy | F1 Score | ROC AUC
--------------------|----------|----------|---------
Logistic Regression | 88%      | 84%      | 0.71
Random Forest       | 88%      | 84%      | 0.71
XGBoost             | 89%      | 85%      | 0.72

All models were tuned using GridSearchCV.

## ğŸ§  Key Features Used

- Engagement Score
- Income
- Ad Spend
- Age Category (encoded)
- Campaign Channel (encoded)
- Previous Purchases

## ğŸ“Š Visual Output

- Confusion Matrix
- ROC Curve
- Feature Importance
- Error Samples (misclassified predictions)

These are saved in the reports/figures/ directory.

## ğŸ’¡ Business Value

By accurately predicting conversion likelihood:
- Marketing campaigns can focus on high-probability customers
- Budgets can be reduced by avoiding outreach to low-conversion segments
- Messaging can be tailored to audience segments with the highest impact


## ğŸ‘¨â€ğŸ’» Author

David Lin  
University of Maryland  
Spring 2025 â€“ INST414 Final Project

## ğŸ“œ License

MIT License


#Author Note
This was completed with the help of an AI assistance tool(Github Copilot, A little ChatGPT) Also confusion matrix is the most helpful visualization in my opinion